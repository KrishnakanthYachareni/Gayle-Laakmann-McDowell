{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: \n",
    "Campus Tech Data Science Coding Assignment\n",
    "\n",
    "### Created by :\n",
    "- Rama Lakkireddy\n",
    "- Date: March 2nd, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libraries for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler # feature scaling library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings #disable the warning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "OriginalData = pd.read_csv(\"DataSet2.csv\") # read the dataset\n",
    "\n",
    "data = pd.read_csv(\"DataSet2.csv\") # read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1700, 12)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking into the shape of data i.e, total number of rows and columns\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>-0.375866</td>\n",
       "      <td>0.427942</td>\n",
       "      <td>-0.922338</td>\n",
       "      <td>0.210758</td>\n",
       "      <td>0.109015</td>\n",
       "      <td>0.621001</td>\n",
       "      <td>-0.444421</td>\n",
       "      <td>0.089970</td>\n",
       "      <td>-0.707711</td>\n",
       "      <td>0.473700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>0.047819</td>\n",
       "      <td>0.115627</td>\n",
       "      <td>-1.781739</td>\n",
       "      <td>-0.272785</td>\n",
       "      <td>0.392783</td>\n",
       "      <td>1.094168</td>\n",
       "      <td>-0.975254</td>\n",
       "      <td>-0.353424</td>\n",
       "      <td>0.145543</td>\n",
       "      <td>-0.064961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "      <td>0.372868</td>\n",
       "      <td>-0.263291</td>\n",
       "      <td>-1.120545</td>\n",
       "      <td>-0.773828</td>\n",
       "      <td>0.830072</td>\n",
       "      <td>-1.727836</td>\n",
       "      <td>1.323876</td>\n",
       "      <td>-1.587291</td>\n",
       "      <td>-0.024916</td>\n",
       "      <td>0.082491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>0.059598</td>\n",
       "      <td>0.270797</td>\n",
       "      <td>0.961795</td>\n",
       "      <td>-1.804197</td>\n",
       "      <td>2.931330</td>\n",
       "      <td>1.891656</td>\n",
       "      <td>0.094252</td>\n",
       "      <td>-0.873467</td>\n",
       "      <td>-1.217680</td>\n",
       "      <td>-1.848046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "      <td>0.616319</td>\n",
       "      <td>0.291275</td>\n",
       "      <td>-1.113519</td>\n",
       "      <td>0.626864</td>\n",
       "      <td>-0.287989</td>\n",
       "      <td>-0.842649</td>\n",
       "      <td>-0.947257</td>\n",
       "      <td>1.198215</td>\n",
       "      <td>0.972420</td>\n",
       "      <td>-1.054313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y x1        x2        x3        x4        x5        x6        x7        x8  \\\n",
       "0  0  a -0.375866  0.427942 -0.922338  0.210758  0.109015  0.621001 -0.444421   \n",
       "1  0  b  0.047819  0.115627 -1.781739 -0.272785  0.392783  1.094168 -0.975254   \n",
       "2  1  d  0.372868 -0.263291 -1.120545 -0.773828  0.830072 -1.727836  1.323876   \n",
       "3  0  c  0.059598  0.270797  0.961795 -1.804197  2.931330  1.891656  0.094252   \n",
       "4  1  d  0.616319  0.291275 -1.113519  0.626864 -0.287989 -0.842649 -0.947257   \n",
       "\n",
       "         x9       x10       x11  \n",
       "0  0.089970 -0.707711  0.473700  \n",
       "1 -0.353424  0.145543 -0.064961  \n",
       "2 -1.587291 -0.024916  0.082491  \n",
       "3 -0.873467 -1.217680 -1.848046  \n",
       "4  1.198215  0.972420 -1.054313  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking into few samples of data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1000\n",
       "1     700\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y'].value_counts() # checking if datset is imbalenced or balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "The given data is a balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y      0\n",
       "x1     0\n",
       "x2     0\n",
       "x3     0\n",
       "x4     0\n",
       "x5     0\n",
       "x6     0\n",
       "x7     0\n",
       "x8     0\n",
       "x9     0\n",
       "x10    0\n",
       "x11    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking missing values, zeros shows that there is no missing value.\n",
    "data.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [y, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11]\n",
       "Index: []"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking duplicate values\n",
    "duplicate_value = data[data.duplicated()]\n",
    "duplicate_value #there is no duplicate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1700 entries, 0 to 1699\n",
      "Data columns (total 12 columns):\n",
      "y      1700 non-null int64\n",
      "x1     1700 non-null object\n",
      "x2     1700 non-null float64\n",
      "x3     1700 non-null float64\n",
      "x4     1700 non-null float64\n",
      "x5     1700 non-null float64\n",
      "x6     1700 non-null float64\n",
      "x7     1700 non-null float64\n",
      "x8     1700 non-null float64\n",
      "x9     1700 non-null float64\n",
      "x10    1700 non-null float64\n",
      "x11    1700 non-null float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 159.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#geting the information related to data types of each column and number of records\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "X1 column is object types that need to converted into numeric form as the ML algorithms does not accept object value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical data in to numerical using pandas\n",
    "data['x1'] = data['x1'].astype(\"category\")\n",
    "data['x1'] = data['x1'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features and labels\n",
    "x = data.drop(columns=['y'])\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting pandas series ojects to numpy arrays\n",
    "x = x.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffleing data and splitting into train and test datasets\n",
    "x,y = shuffle(x,y,random_state=1)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy  0.9992647058823529\n",
      " Testing accuracy  0.9882352941176471\n",
      " Confusion matrix\n",
      "[[190   2]\n",
      " [  2 146]]\n",
      "F1 Score  0.9864864864864865\n",
      "Predit Probabilities  [[0.   1.  ]\n",
      " [0.95 0.05]\n",
      " [0.95 0.05]\n",
      " [0.95 0.05]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [0.15 0.85]\n",
      " [0.6  0.4 ]\n",
      " [1.   0.  ]\n",
      " [0.15 0.85]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.85 0.15]\n",
      " [0.2  0.8 ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.85 0.15]\n",
      " [0.95 0.05]\n",
      " [0.95 0.05]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.7  0.3 ]\n",
      " [0.95 0.05]\n",
      " [0.15 0.85]\n",
      " [1.   0.  ]\n",
      " [0.1  0.9 ]\n",
      " [0.9  0.1 ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.95 0.05]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.1  0.9 ]\n",
      " [0.05 0.95]\n",
      " [0.05 0.95]\n",
      " [0.85 0.15]\n",
      " [0.7  0.3 ]\n",
      " [1.   0.  ]\n",
      " [0.1  0.9 ]\n",
      " [0.1  0.9 ]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [0.15 0.85]\n",
      " [1.   0.  ]\n",
      " [0.9  0.1 ]\n",
      " [1.   0.  ]\n",
      " [0.85 0.15]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [0.   1.  ]\n",
      " [0.95 0.05]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.25 0.75]\n",
      " [0.9  0.1 ]\n",
      " [0.95 0.05]\n",
      " [0.95 0.05]\n",
      " [0.8  0.2 ]\n",
      " [0.1  0.9 ]\n",
      " [1.   0.  ]\n",
      " [0.95 0.05]\n",
      " [0.2  0.8 ]\n",
      " [0.05 0.95]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [1.   0.  ]\n",
      " [0.95 0.05]\n",
      " [1.   0.  ]\n",
      " [0.95 0.05]\n",
      " [0.15 0.85]\n",
      " [0.9  0.1 ]\n",
      " [0.1  0.9 ]\n",
      " [0.9  0.1 ]\n",
      " [1.   0.  ]\n",
      " [0.85 0.15]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.95 0.05]\n",
      " [0.   1.  ]\n",
      " [0.1  0.9 ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.95 0.05]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [0.25 0.75]\n",
      " [0.35 0.65]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [0.15 0.85]\n",
      " [0.05 0.95]\n",
      " [0.05 0.95]\n",
      " [0.95 0.05]\n",
      " [0.8  0.2 ]\n",
      " [0.95 0.05]\n",
      " [0.9  0.1 ]\n",
      " [0.2  0.8 ]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [0.05 0.95]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [0.3  0.7 ]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [0.95 0.05]\n",
      " [0.95 0.05]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.1  0.9 ]\n",
      " [0.95 0.05]\n",
      " [0.05 0.95]\n",
      " [0.05 0.95]\n",
      " [0.95 0.05]\n",
      " [1.   0.  ]\n",
      " [0.9  0.1 ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.05 0.95]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [0.   1.  ]\n",
      " [0.95 0.05]\n",
      " [0.65 0.35]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.95 0.05]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [0.95 0.05]\n",
      " [1.   0.  ]\n",
      " [0.95 0.05]\n",
      " [0.05 0.95]\n",
      " [0.95 0.05]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.95 0.05]\n",
      " [0.05 0.95]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.1  0.9 ]\n",
      " [0.9  0.1 ]\n",
      " [0.95 0.05]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [0.95 0.05]\n",
      " [0.9  0.1 ]\n",
      " [0.9  0.1 ]\n",
      " [0.9  0.1 ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.85 0.15]\n",
      " [1.   0.  ]\n",
      " [0.1  0.9 ]\n",
      " [0.1  0.9 ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.1  0.9 ]\n",
      " [0.   1.  ]\n",
      " [0.25 0.75]\n",
      " [0.   1.  ]\n",
      " [0.85 0.15]\n",
      " [0.15 0.85]\n",
      " [0.9  0.1 ]\n",
      " [0.95 0.05]\n",
      " [0.95 0.05]\n",
      " [0.95 0.05]\n",
      " [0.85 0.15]\n",
      " [0.05 0.95]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.95 0.05]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.95 0.05]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.95 0.05]\n",
      " [1.   0.  ]\n",
      " [0.1  0.9 ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.05 0.95]\n",
      " [1.   0.  ]\n",
      " [0.1  0.9 ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.85 0.15]\n",
      " [0.05 0.95]\n",
      " [0.85 0.15]\n",
      " [0.05 0.95]\n",
      " [0.1  0.9 ]\n",
      " [1.   0.  ]\n",
      " [0.2  0.8 ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.95 0.05]\n",
      " [1.   0.  ]\n",
      " [0.15 0.85]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.05 0.95]\n",
      " [0.05 0.95]\n",
      " [0.05 0.95]\n",
      " [1.   0.  ]\n",
      " [0.9  0.1 ]\n",
      " [0.   1.  ]\n",
      " [0.05 0.95]\n",
      " [0.9  0.1 ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.85 0.15]\n",
      " [0.95 0.05]\n",
      " [0.   1.  ]\n",
      " [0.15 0.85]\n",
      " [0.95 0.05]\n",
      " [0.9  0.1 ]\n",
      " [0.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.95 0.05]\n",
      " [0.95 0.05]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.95 0.05]\n",
      " [0.05 0.95]\n",
      " [0.25 0.75]\n",
      " [0.   1.  ]\n",
      " [0.95 0.05]\n",
      " [0.25 0.75]\n",
      " [1.   0.  ]\n",
      " [0.1  0.9 ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.95 0.05]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.9  0.1 ]\n",
      " [0.9  0.1 ]\n",
      " [0.1  0.9 ]\n",
      " [0.95 0.05]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.9  0.1 ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.8  0.2 ]\n",
      " [0.95 0.05]\n",
      " [0.9  0.1 ]\n",
      " [1.   0.  ]\n",
      " [0.15 0.85]\n",
      " [0.1  0.9 ]\n",
      " [0.05 0.95]\n",
      " [0.75 0.25]\n",
      " [0.1  0.9 ]\n",
      " [1.   0.  ]\n",
      " [0.9  0.1 ]\n",
      " [0.05 0.95]\n",
      " [0.05 0.95]\n",
      " [0.95 0.05]\n",
      " [0.1  0.9 ]\n",
      " [1.   0.  ]\n",
      " [0.1  0.9 ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [0.3  0.7 ]\n",
      " [1.   0.  ]\n",
      " [0.   1.  ]\n",
      " [0.9  0.1 ]\n",
      " [0.35 0.65]\n",
      " [1.   0.  ]\n",
      " [0.1  0.9 ]\n",
      " [0.   1.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.15 0.85]\n",
      " [0.1  0.9 ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.95 0.05]\n",
      " [0.05 0.95]\n",
      " [0.   1.  ]\n",
      " [0.05 0.95]\n",
      " [1.   0.  ]\n",
      " [0.85 0.15]\n",
      " [0.1  0.9 ]\n",
      " [0.95 0.05]\n",
      " [0.9  0.1 ]\n",
      " [0.15 0.85]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.95 0.05]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "#Random forest classifier training\n",
    "rf_clf = make_pipeline(StandardScaler(with_mean=False,with_std=False), RandomForestClassifier(n_estimators=20))\n",
    "rf_clf.fit(x_train,y_train)\n",
    "print(\" Training accuracy \",accuracy_score(y_train,rf_clf.predict(x_train)))\n",
    "print(\" Testing accuracy \",accuracy_score(y_test,rf_clf.predict(x_test)))\n",
    "print(\" Confusion matrix\")\n",
    "print(confusion_matrix(y_test,rf_clf.predict(x_test)))\n",
    "print(\"F1 Score \",f1_score(y_test,rf_clf.predict(x_test),'binary'))\n",
    "print(\"Predit Probabilities \", rf_clf.predict_proba(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "1. __True Negative__ - represents the values which are predicted to be false and are actually false.\n",
    "2. __False Positive__ - represents the values which are predicted to be true, but are false.\n",
    "3. __False Negative__ - represents the values which are predicted to be false, but are true.\n",
    "4. __True Positive__ - represents the values which are predicted to be true and are actually true.\n",
    "\n",
    "### False Positive (type I error)\n",
    "When we predict that something happens/occurs and it didn't happened/occured.(rejection of a true null hypothesis) Example :- We predict that an earthquake would occur which didn't happen.\n",
    "\n",
    "### False Negative (type II error)\n",
    "When we predict that something won't happen/occur but it happens/occurs.(non-rejection of a false null hypothesis) Example :- We predict that there might be no earthquake but there occurs an earthquake.\n",
    "\n",
    "Usually, type I errors are considered to be not as critical as type II errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>98.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>98.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>98.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False_Positive_Rate</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Misclassification_Rate</th>\n",
       "      <td>1.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>98.823529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "Sensitivity             98.648649\n",
       "Specificity             98.958333\n",
       "Precision               98.648649\n",
       "False_Positive_Rate     50.000000\n",
       "Misclassification_Rate   1.176471\n",
       "Accuracy                98.823529"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix Stats\n",
    "TN = 190 \n",
    "FN = 2   \n",
    "FP = 2   \n",
    "TP = 146 \n",
    "\n",
    "# Confusion matrix stats and metrics into a dataframe for easy reading and interpretation\n",
    "cm_d = {'Sensitivity': [(TP/(TP+FN))*100], 'Specificity': [(TN/(TN+FP))*100], 'Precision': [(TP/(TP+FP))*100], 'False_Positive_Rate': [((FP)/(FN+FP))*100], 'Misclassification_Rate': [(FP+FN)/(TN+FN+FP+TP)*100], 'Accuracy': [(TP + TN)/(TN+FN+FP+TP)*100]}\n",
    "cm_metrics = pd.DataFrame(data = cm_d)\n",
    "cm_metrics.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Table Metrics\n",
    "1. __Sensitivity__ = (TP/(TP+FN)) \n",
    "2. __Specificity__ = (TN/(TN+FP))\n",
    "3. __Precision__ = (TP/(TP+FP))\n",
    "4. __False_Positive_Rate__ = (FP/(FN+FP))\n",
    "5. __Misclassification_Rate__ = (FP+FN)/(TN+FN+FP+TP)\n",
    "6. __Accuracy__ = (TP + TN)/(TN+FN+FP+TP)\n",
    "7. __Rate of Success__ = (TP+TN)/(FP+FN)\n",
    "8. __Precision__ = TP/(TP+FP)\n",
    "9. __Recall__ = TP/(TP+FN)\n",
    "10. __F1 score__ = 2*Precision * Recall/(Precision+Recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier\n",
    "\n",
    "In Naive Bayes, we are cluclating the posterior probability using the prior probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy  0.8669117647058824\n",
      " Testing accuracy  0.8529411764705882\n",
      " Confusion matrix\n",
      "[[154  38]\n",
      " [ 12 136]]\n",
      "F1 Score  0.84472049689441\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes classifier training\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB_clf = make_pipeline(StandardScaler(with_mean=False,with_std=False), GaussianNB())\n",
    "NB_clf.fit(x_train,y_train)\n",
    "print(\" Training accuracy \",accuracy_score(y_train,NB_clf.predict(x_train)))\n",
    "print(\" Testing accuracy \",accuracy_score(y_test,NB_clf.predict(x_test)))\n",
    "print(\" Confusion matrix\")\n",
    "print(confusion_matrix(y_test,NB_clf.predict(x_test)))\n",
    "print(\"F1 Score \",f1_score(y_test,NB_clf.predict(x_test),'binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy  0.9191176470588235\n",
      " Testing accuracy  0.8794117647058823\n",
      " Confusion matrix\n",
      "[[168  24]\n",
      " [ 17 131]]\n",
      "F1 Score  0.8646864686468647\n"
     ]
    }
   ],
   "source": [
    "# Support Vector classifier training\n",
    "from sklearn.svm import SVC\n",
    "svc_clf = make_pipeline(StandardScaler(with_mean=False,with_std=False), SVC())\n",
    "svc_clf.fit(x_train,y_train)\n",
    "print(\" Training accuracy \",accuracy_score(y_train,svc_clf.predict(x_train)))\n",
    "print(\" Testing accuracy \",accuracy_score(y_test,svc_clf.predict(x_test)))\n",
    "print(\" Confusion matrix\")\n",
    "print(confusion_matrix(y_test,svc_clf.predict(x_test)))\n",
    "print(\"F1 Score \",f1_score(y_test,svc_clf.predict(x_test),'binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question a)\n",
    "\n",
    "why it is the best model? Give an example of a data point that model doesn’t do well and explain\n",
    "the characteristics of that observation. How- do you see the limitations of your model? How do you plan to\n",
    "improve it?\n",
    "\n",
    "### Solution\n",
    "1. Random forest classifier is the best model because the difference between the Training accuracy and the Testing accuracy is very minimal.\n",
    "2. The F-1 score is very good for the Random forest classifier model 0.98 and have less false negatives.\n",
    "2. I performed Random Forest with ensemble algorithm model and predicted with 20 decision trees. The best prediction will be made since more models are working on the dataset, and will choose the best output based on voting.\n",
    "3. We can use the probabilities of the prediction of the model and decide whether the sample belongs to calss0 or class1, If both probabilities are very near like 0.67,0.43 or 0.5,0.5, Then we can say they are confusing examples for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question b(1)\n",
    "A few days after you finish the initial model, you learn new information that the value of the X2 feature\n",
    "makes sense only if it is positive (i.e. X2> 0 should be in the model instead of original X2). Show how you would address this issue.\n",
    "\n",
    "### Solution:\n",
    "1. I have used StandardScaler with mean = False and StandardDeviation = False to standerdize the data.\n",
    "2. It wil scale the dataset to Mean 0 and StandardDeviation to 1. \n",
    "3. The standard score of a sample x is calculated as z=(x-u)/s, Where x = value of x1, u is mean of the x1 column and    s is the standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>0.047819</td>\n",
       "      <td>0.115627</td>\n",
       "      <td>-1.781739</td>\n",
       "      <td>-0.272785</td>\n",
       "      <td>0.392783</td>\n",
       "      <td>1.094168</td>\n",
       "      <td>-0.975254</td>\n",
       "      <td>-0.353424</td>\n",
       "      <td>0.145543</td>\n",
       "      <td>-0.064961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "      <td>0.372868</td>\n",
       "      <td>-0.263291</td>\n",
       "      <td>-1.120545</td>\n",
       "      <td>-0.773828</td>\n",
       "      <td>0.830072</td>\n",
       "      <td>-1.727836</td>\n",
       "      <td>1.323876</td>\n",
       "      <td>-1.587291</td>\n",
       "      <td>-0.024916</td>\n",
       "      <td>0.082491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>0.059598</td>\n",
       "      <td>0.270797</td>\n",
       "      <td>0.961795</td>\n",
       "      <td>-1.804197</td>\n",
       "      <td>2.931330</td>\n",
       "      <td>1.891656</td>\n",
       "      <td>0.094252</td>\n",
       "      <td>-0.873467</td>\n",
       "      <td>-1.217680</td>\n",
       "      <td>-1.848046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "      <td>0.616319</td>\n",
       "      <td>0.291275</td>\n",
       "      <td>-1.113519</td>\n",
       "      <td>0.626864</td>\n",
       "      <td>-0.287989</td>\n",
       "      <td>-0.842649</td>\n",
       "      <td>-0.947257</td>\n",
       "      <td>1.198215</td>\n",
       "      <td>0.972420</td>\n",
       "      <td>-1.054313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>0.142068</td>\n",
       "      <td>0.345289</td>\n",
       "      <td>-1.460133</td>\n",
       "      <td>-0.532363</td>\n",
       "      <td>0.758932</td>\n",
       "      <td>0.774621</td>\n",
       "      <td>-0.822781</td>\n",
       "      <td>-0.494892</td>\n",
       "      <td>-1.736284</td>\n",
       "      <td>-1.076106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>0.607494</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>-1.238585</td>\n",
       "      <td>-0.487627</td>\n",
       "      <td>0.523256</td>\n",
       "      <td>0.491626</td>\n",
       "      <td>-0.909850</td>\n",
       "      <td>-0.427637</td>\n",
       "      <td>0.887907</td>\n",
       "      <td>0.565468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.164728</td>\n",
       "      <td>-0.238624</td>\n",
       "      <td>0.057843</td>\n",
       "      <td>-0.631889</td>\n",
       "      <td>-0.121608</td>\n",
       "      <td>0.551179</td>\n",
       "      <td>1.154057</td>\n",
       "      <td>0.520261</td>\n",
       "      <td>-0.493283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>0.503167</td>\n",
       "      <td>-0.230747</td>\n",
       "      <td>-1.704355</td>\n",
       "      <td>-0.459350</td>\n",
       "      <td>-0.578345</td>\n",
       "      <td>-2.201978</td>\n",
       "      <td>0.785508</td>\n",
       "      <td>-0.533763</td>\n",
       "      <td>0.540966</td>\n",
       "      <td>0.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.355344</td>\n",
       "      <td>0.118125</td>\n",
       "      <td>-0.325976</td>\n",
       "      <td>0.558218</td>\n",
       "      <td>0.345394</td>\n",
       "      <td>-0.588490</td>\n",
       "      <td>0.440795</td>\n",
       "      <td>-0.158578</td>\n",
       "      <td>0.651394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>0.541717</td>\n",
       "      <td>0.072494</td>\n",
       "      <td>-1.571099</td>\n",
       "      <td>0.241235</td>\n",
       "      <td>-1.694391</td>\n",
       "      <td>-0.523919</td>\n",
       "      <td>0.440969</td>\n",
       "      <td>-0.099387</td>\n",
       "      <td>1.268869</td>\n",
       "      <td>1.010457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>907 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y x1        x2        x3        x4        x5        x6        x7  \\\n",
       "1     0  b  0.047819  0.115627 -1.781739 -0.272785  0.392783  1.094168   \n",
       "2     1  d  0.372868 -0.263291 -1.120545 -0.773828  0.830072 -1.727836   \n",
       "3     0  c  0.059598  0.270797  0.961795 -1.804197  2.931330  1.891656   \n",
       "4     1  d  0.616319  0.291275 -1.113519  0.626864 -0.287989 -0.842649   \n",
       "6     0  c  0.142068  0.345289 -1.460133 -0.532363  0.758932  0.774621   \n",
       "...  .. ..       ...       ...       ...       ...       ...       ...   \n",
       "1689  1  b  0.607494  0.011744 -1.238585 -0.487627  0.523256  0.491626   \n",
       "1690  1  c  0.675912  0.164728 -0.238624  0.057843 -0.631889 -0.121608   \n",
       "1692  1  b  0.503167 -0.230747 -1.704355 -0.459350 -0.578345 -2.201978   \n",
       "1693  0  c  0.002887  0.355344  0.118125 -0.325976  0.558218  0.345394   \n",
       "1695  1  c  0.541717  0.072494 -1.571099  0.241235 -1.694391 -0.523919   \n",
       "\n",
       "            x8        x9       x10       x11  \n",
       "1    -0.975254 -0.353424  0.145543 -0.064961  \n",
       "2     1.323876 -1.587291 -0.024916  0.082491  \n",
       "3     0.094252 -0.873467 -1.217680 -1.848046  \n",
       "4    -0.947257  1.198215  0.972420 -1.054313  \n",
       "6    -0.822781 -0.494892 -1.736284 -1.076106  \n",
       "...        ...       ...       ...       ...  \n",
       "1689 -0.909850 -0.427637  0.887907  0.565468  \n",
       "1690  0.551179  1.154057  0.520261 -0.493283  \n",
       "1692  0.785508 -0.533763  0.540966  0.474100  \n",
       "1693 -0.588490  0.440795 -0.158578  0.651394  \n",
       "1695  0.440969 -0.099387  1.268869  1.010457  \n",
       "\n",
       "[907 rows x 12 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = OriginalData[OriginalData['x2'] > 0]\n",
    "data1\n",
    "#data = data[data['x2'] > 0] #To execute in one single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy  1.0\n",
      " Testing accuracy  1.0\n",
      " Confusion matrix\n",
      "[[ 77   0]\n",
      " [  0 105]]\n",
      "F1 Score  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Converting categorical data in to numerical using pandas\n",
    "data1['x1'] = data1['x1'].astype(\"category\")\n",
    "data1['x1'] = data1['x1'].cat.codes\n",
    "\n",
    "# Splitting data into features and labels\n",
    "x = data1.drop(columns=['y'])\n",
    "y = data1['y']\n",
    "\n",
    "#Converting pandas series ojects to numpy arrays\n",
    "x = x.values\n",
    "y = y.values\n",
    "\n",
    "#Shuffleing data and splitting into train and test datasets\n",
    "x,y = shuffle(x,y,random_state=1)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)\n",
    "\n",
    "#Random forest classifier training\n",
    "rf_clf = make_pipeline(StandardScaler(with_mean=False,with_std=False), RandomForestClassifier(n_estimators=20))\n",
    "rf_clf.fit(x_train,y_train)\n",
    "print(\" Training accuracy \",accuracy_score(y_train,rf_clf.predict(x_train)))\n",
    "print(\" Testing accuracy \",accuracy_score(y_test,rf_clf.predict(x_test)))\n",
    "print(\" Confusion matrix\")\n",
    "print(confusion_matrix(y_test,rf_clf.predict(x_test)))\n",
    "print(\"F1 Score \",f1_score(y_test,rf_clf.predict(x_test),'binary'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question b(2)\n",
    "Later, you additionally learn that X4 should’ve been used as an indicator variable (e.g. X4 that is greater than\n",
    "   a certain threshold should be treated differently than X4 values below that threshold). However, you don’t\n",
    "   know the value of threshold. Adapt your code to support a systematic way of finding threshold which leads\n",
    "   to improved model performance.\n",
    "   \n",
    "### Solution\n",
    "Though I did the standard scalar it's not mandatory for all features to be in the same ranges(o to 1 or -1 to 1). There will be various ranges but the mean will be 0 and the StandardDeviation will be 1 and all the values will be with in the same pattern. It will be easy for the MachineLearning Algorithm to grasp the pattern inside the data and easily predict the things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>0.059598</td>\n",
       "      <td>0.270797</td>\n",
       "      <td>0.961795</td>\n",
       "      <td>-1.804197</td>\n",
       "      <td>2.931330</td>\n",
       "      <td>1.891656</td>\n",
       "      <td>0.094252</td>\n",
       "      <td>-0.873467</td>\n",
       "      <td>-1.217680</td>\n",
       "      <td>-1.848046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>-0.716144</td>\n",
       "      <td>0.259650</td>\n",
       "      <td>0.799474</td>\n",
       "      <td>-1.058823</td>\n",
       "      <td>-0.505464</td>\n",
       "      <td>2.202489</td>\n",
       "      <td>1.507675</td>\n",
       "      <td>1.245329</td>\n",
       "      <td>-2.106922</td>\n",
       "      <td>-0.421270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0.599369</td>\n",
       "      <td>0.062345</td>\n",
       "      <td>0.877789</td>\n",
       "      <td>0.171441</td>\n",
       "      <td>0.078635</td>\n",
       "      <td>-1.624168</td>\n",
       "      <td>-0.995793</td>\n",
       "      <td>1.162826</td>\n",
       "      <td>0.106844</td>\n",
       "      <td>2.119611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>-0.583062</td>\n",
       "      <td>0.364628</td>\n",
       "      <td>0.779796</td>\n",
       "      <td>-1.365581</td>\n",
       "      <td>-0.636767</td>\n",
       "      <td>0.024686</td>\n",
       "      <td>-0.013499</td>\n",
       "      <td>1.690769</td>\n",
       "      <td>-0.842906</td>\n",
       "      <td>-0.675950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>-0.099098</td>\n",
       "      <td>0.256639</td>\n",
       "      <td>-1.494390</td>\n",
       "      <td>-0.452845</td>\n",
       "      <td>1.346259</td>\n",
       "      <td>-0.828126</td>\n",
       "      <td>0.559479</td>\n",
       "      <td>-1.149758</td>\n",
       "      <td>-0.524137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>-0.854529</td>\n",
       "      <td>-0.187580</td>\n",
       "      <td>0.916175</td>\n",
       "      <td>-0.095200</td>\n",
       "      <td>-0.627267</td>\n",
       "      <td>1.466028</td>\n",
       "      <td>-0.199312</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>0.432920</td>\n",
       "      <td>-0.871332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.355344</td>\n",
       "      <td>0.118125</td>\n",
       "      <td>-0.325976</td>\n",
       "      <td>0.558218</td>\n",
       "      <td>0.345394</td>\n",
       "      <td>-0.588490</td>\n",
       "      <td>0.440795</td>\n",
       "      <td>-0.158578</td>\n",
       "      <td>0.651394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>0</td>\n",
       "      <td>d</td>\n",
       "      <td>-0.505463</td>\n",
       "      <td>0.412871</td>\n",
       "      <td>0.207284</td>\n",
       "      <td>-0.011785</td>\n",
       "      <td>0.642973</td>\n",
       "      <td>1.374254</td>\n",
       "      <td>0.409001</td>\n",
       "      <td>1.168988</td>\n",
       "      <td>-0.077401</td>\n",
       "      <td>0.211484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>-0.448287</td>\n",
       "      <td>0.359409</td>\n",
       "      <td>0.983409</td>\n",
       "      <td>-1.057294</td>\n",
       "      <td>-0.501924</td>\n",
       "      <td>0.808380</td>\n",
       "      <td>-1.330170</td>\n",
       "      <td>3.595073</td>\n",
       "      <td>-0.716719</td>\n",
       "      <td>-0.891881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>-0.778458</td>\n",
       "      <td>-0.260288</td>\n",
       "      <td>1.818800</td>\n",
       "      <td>-0.224182</td>\n",
       "      <td>-0.311970</td>\n",
       "      <td>-1.933239</td>\n",
       "      <td>-1.097035</td>\n",
       "      <td>-0.158764</td>\n",
       "      <td>-1.003412</td>\n",
       "      <td>1.239610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>852 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y x1        x2        x3        x4        x5        x6        x7  \\\n",
       "3     0  c  0.059598  0.270797  0.961795 -1.804197  2.931330  1.891656   \n",
       "5     0  c -0.716144  0.259650  0.799474 -1.058823 -0.505464  2.202489   \n",
       "9     1  a  0.599369  0.062345  0.877789  0.171441  0.078635 -1.624168   \n",
       "10    0  a -0.583062  0.364628  0.779796 -1.365581 -0.636767  0.024686   \n",
       "11    1  c  0.000381 -0.099098  0.256639 -1.494390 -0.452845  1.346259   \n",
       "...  .. ..       ...       ...       ...       ...       ...       ...   \n",
       "1691  0  c -0.854529 -0.187580  0.916175 -0.095200 -0.627267  1.466028   \n",
       "1693  0  c  0.002887  0.355344  0.118125 -0.325976  0.558218  0.345394   \n",
       "1694  0  d -0.505463  0.412871  0.207284 -0.011785  0.642973  1.374254   \n",
       "1698  0  c -0.448287  0.359409  0.983409 -1.057294 -0.501924  0.808380   \n",
       "1699  0  b -0.778458 -0.260288  1.818800 -0.224182 -0.311970 -1.933239   \n",
       "\n",
       "            x8        x9       x10       x11  \n",
       "3     0.094252 -0.873467 -1.217680 -1.848046  \n",
       "5     1.507675  1.245329 -2.106922 -0.421270  \n",
       "9    -0.995793  1.162826  0.106844  2.119611  \n",
       "10   -0.013499  1.690769 -0.842906 -0.675950  \n",
       "11   -0.828126  0.559479 -1.149758 -0.524137  \n",
       "...        ...       ...       ...       ...  \n",
       "1691 -0.199312  0.005658  0.432920 -0.871332  \n",
       "1693 -0.588490  0.440795 -0.158578  0.651394  \n",
       "1694  0.409001  1.168988 -0.077401  0.211484  \n",
       "1698 -1.330170  3.595073 -0.716719 -0.891881  \n",
       "1699 -1.097035 -0.158764 -1.003412  1.239610  \n",
       "\n",
       "[852 rows x 12 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = OriginalData[OriginalData['x4'] > 0] # Consider the threshold value as 0\n",
    "data2\n",
    "#data = data[data['x4'] > 0] #To execute in one single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy  1.0\n",
      " Testing accuracy  0.9941520467836257\n",
      " Confusion matrix\n",
      "[[93  1]\n",
      " [ 0 77]]\n",
      "F1 Score  0.9935483870967742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Converting categorical data in to numerical using pandas\n",
    "data2['x1'] = data2['x1'].astype(\"category\")\n",
    "data2['x1'] = data2['x1'].cat.codes\n",
    "\n",
    "# Splitting data into features and labels\n",
    "x = data2.drop(columns=['y'])\n",
    "y = data2['y']\n",
    "\n",
    "#Converting pandas series ojects to numpy arrays\n",
    "x = x.values\n",
    "y = y.values\n",
    "\n",
    "#Shuffleing data and splitting into train and test datasets\n",
    "x,y = shuffle(x,y,random_state=1)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)\n",
    "\n",
    "#Random forest classifier training\n",
    "rf_clf = make_pipeline(StandardScaler(with_mean=False,with_std=False), RandomForestClassifier(n_estimators=20))\n",
    "rf_clf.fit(x_train,y_train)\n",
    "print(\" Training accuracy \",accuracy_score(y_train,rf_clf.predict(x_train)))\n",
    "print(\" Testing accuracy \",accuracy_score(y_test,rf_clf.predict(x_test)))\n",
    "print(\" Confusion matrix\")\n",
    "print(confusion_matrix(y_test,rf_clf.predict(x_test)))\n",
    "print(\"F1 Score \",f1_score(y_test,rf_clf.predict(x_test),'binary'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question b(3)\n",
    "Now that you realize feature engineering is a frequent need for improving our models, you want to create a\n",
    "general framework to tackle such situations (e.g. conversion to indicators, defining certain thresholds, etc.).\n",
    "What function/module do you develop to enable user-defined column conversions for given thresholds?\n",
    "Suppose thresholds are given to you as arguments to your function.\n",
    "\n",
    "### Solution\n",
    "1. I have used the make_pipeline and StandardScaler. \n",
    "2. So, the StandardScler will scale the data and tackle the issues of feature scaling and make the Mean to 0 and Standard Deviation as 1 and normalize the data and apply the model to it.\n",
    "3. So, here we are automating the process and making the model resistent to tackle situations like x2>0 and threshold values.\n",
    "4. In the future, we can add any further pre processing steps to the make_pipeline method.\n",
    "\n",
    "### Conclusion\n",
    "1. Ensemble Random Forest classifier algorithm perfomred well when compared with the Naiv eBayes and the Support Vector Machine algorithms. \n",
    "2. Make_Pipeline and StandardScaler are used to automate the process of predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
